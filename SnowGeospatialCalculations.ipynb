{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snow Geospatial Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray as rio \n",
    "# import leafmap.leafmap as leafmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    " ####  [Process Snow Data](#bullet1)\n",
    " * [Calculate Monthly Snow Cover Averages](#bullet2)\n",
    " * [Calculate Snow Cover Anomolies Per Month Per Year](#bullet5)\n",
    " * [Select Indivdual Snow Cover Years and Months](#bullet6)\n",
    " #### [Process Albedo Data](#bullet7)\n",
    " * [Calculate Monthly Albedo Averages](#bullet8)\n",
    " * [Calculate Albedo Anomalies Per Month Per Year](#bullet10)\n",
    " * [Select Indivdual Years and Months for Albedo](#bullet11)\n",
    " #### [Convert Datasets to GeoTIFF](#bullet12)\n",
    " * [Define Geospatial Inputs](#bullet3)\n",
    " * [Convert Array to Geotiff](#bullet13)\n",
    " * [Convert Stacked Array into Multiple Geotiffs](#bullet14)\n",
    " * [Transform Geotiff to WGS84 Coordinate System](#bullet15)\n",
    " * [Transform Geotiff to NetCDF File](#bullet16)\n",
    " #### [Plot Geotiffs Using Leafmap](#bullet17)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Snow Cover Data <a class=\"anchor\" id=\"bullet1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sierra2001.h5',\n",
       " 'Sierra2002.h5',\n",
       " 'Sierra2003.h5',\n",
       " 'Sierra2004.h5',\n",
       " 'Sierra2005.h5',\n",
       " 'Sierra2006.h5',\n",
       " 'Sierra2007.h5',\n",
       " 'Sierra2008.h5',\n",
       " 'Sierra2009.h5',\n",
       " 'Sierra2010.h5',\n",
       " 'Sierra2011.h5',\n",
       " 'Sierra2012.h5',\n",
       " 'Sierra2013.h5',\n",
       " 'Sierra2014.h5',\n",
       " 'Sierra2015.h5',\n",
       " 'Sierra2016.h5',\n",
       " 'Sierra2017.h5',\n",
       " 'Sierra2018.h5',\n",
       " 'Sierra2019.h5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Glob together all of the Snow Fraction datasets.\n",
    "snow_ds = glob.glob('Sierra20*.h5')\n",
    "snow_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subdatasets of first snow fraction dataset ('Sierra2001.h5').\n",
    "datasets = gdal.Open(snow_ds[0], gdal.GA_ReadOnly).GetSubDatasets()\n",
    "\n",
    "#(sds[3] is to choose the 4th dataset in the subdirectory (i.e., snow fraction). \n",
    "#The second bracket [0] is needed to open the dataset.\n",
    "snow_data = gdal.Open(datasets[3][0])\n",
    "\n",
    "#Changes the selected dataset into an array.\n",
    "snow_data_array = snow_data.ReadAsArray()\n",
    "\n",
    "#Converts the variables to 'float' to allow us to convert NA values (255) to nans\n",
    "#We also convert 0s to nans so that when plotted on base map, only areas where data is present are shown\n",
    "snow_data_float=snow_data_array.astype('float')\n",
    "snow_data_float[snow_data_float == 255] = np.nan\n",
    "\n",
    "snow_data_transposed = np.transpose(snow_data_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcuate Monthly Snow Cover Averages<a class=\"anchor\" id=\"bullet2\"></a>\n",
    "\n",
    "#### Single Year Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to append our calculated values to. \n",
    "month_list = []\n",
    "\n",
    "# Test to see if we can create a range of dates starting at '2000-10-01', the first date of our first year. (Water years count from the year prior).\n",
    "start_date = (str(2000) + '-10-01')\n",
    "end_date = (str(int(2000) + 1) + '-09-30')\n",
    "\n",
    "# Creates a list of datetimes based on each year in our dataset.\n",
    "# start = start of the water year\n",
    "# end = end of water year\n",
    "# freq = frequency of series (in this case days)\n",
    "year_month_day = pd.Series(pd.date_range(start = start_date, end = end_date, freq=\"d\"))\n",
    "\n",
    "month = year_month_day[year_month_day.dt.month == 6]\n",
    "\n",
    "# Since our year_month_day variable starts and ends at the same time as our dataset(e.g., 20xx-10-01 to 20xx-09-03), we can use the subset the months our dataset by the lists index.\n",
    "# However, as Python counts from 0 onward, and we are interested in the physical values for dates, we need to add 1 to our first and last month values (e.g., change 0-30 to 1-31)\n",
    "first_day_month = month.index[0].astype('int') + 1 \n",
    "last_day_month = month.index[-1].astype('int') + 1\n",
    "        # Subset our yearly data by each months values.\n",
    "month_len = snow_data_transposed[:,:,first_day_month:last_day_month]\n",
    "# Takes the mean of each cell in x and y dimensions over the specific month. \n",
    "# Axis 2 aligns with our 3rd dimension, which are days in this case.  \n",
    "mean = np.mean(month_len, axis = 2)\n",
    "# Appends the values to an empty list.\n",
    "month_list.append(mean)\n",
    "# Converts list to an array. \n",
    "month_array = np.array(month_list)\n",
    "# Our array has 3-dimensions (first dimension being month_mean) so we need to subset the data to be 2 dimensions. \n",
    "month_array = month_array[0,:,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Loop Through Each Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 12, 1841, 1334)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty list to append our values to. \n",
    "snow_monthly_means_list = []\n",
    "for i in range(len(snow_ds)):\n",
    "    # Get subdatasets of first snow fraction dataset ('Sierra2001.h5').\n",
    "    datasets = gdal.Open(snow_ds[i], gdal.GA_ReadOnly).GetSubDatasets()\n",
    "\n",
    "    #(sds[3] is to choose the 4th dataset in the subdirectory (i.e., snow fraction). \n",
    "    #The second bracket [0] is needed to open the dataset.\n",
    "    snow_data = gdal.Open(datasets[3][0])\n",
    "\n",
    "    #Changes the selected dataset into an array.\n",
    "    snow_data_array = snow_data.ReadAsArray()\n",
    "\n",
    "    #Converts the variables to 'float' to allow us to convert NA values (255) to nans\n",
    "    #We also convert 0s to nans so that when plotted on base map, only areas where data is present are shown\n",
    "    snow_data_float=snow_data_array.astype('float')\n",
    "    snow_data_float[snow_data_float == 255] = np.nan\n",
    "    snow_data_float[snow_data_float == 0 ] = np.nan\n",
    "\n",
    "    # Need to transpose our data to orient the data values in the right direction for plotting. \n",
    "    sf_tanspoed = np.transpose(snow_data_float)\n",
    "    \n",
    "    # Make a variable for the starting year of each water year.\n",
    "    year =  i + 2000\n",
    "    # Creates a variable for the end date in the water year. \n",
    "    start_date = (str(year) + '-10-01')\n",
    "    end_date = (str(int(year) + 1) + '-09-30')\n",
    "\n",
    "    # Creates a list of datetimes based on each year in our dataset.\n",
    "    # start = start of the water year\n",
    "    # end = end of water year\n",
    "    # freq = frequency of series (in this case days)\n",
    "    year_month_day = pd.Series(pd.date_range(start = start_date, end = end_date, freq=\"d\"))\n",
    "    #Need to create an empty list to append our nest for loop values to. \n",
    "    new_list = []\n",
    "    # For loop to calculate the mean for each month per year. \n",
    "    for j in range (1, 13):\n",
    "        # Subset the date year we just created based on month each month. \n",
    "        month = year_month_day[year_month_day.dt.month == j]\n",
    "\n",
    "        # Since our year_month_day variable starts and ends at the same time as our dataset(e.g., 20xx-10-01 to 20xx-09-03), we can use the subset the months our dataset by the lists index.\n",
    "        # However, as Python counts from 0 onward, and we are interested in the physical values for dates, we need to add 1 to our first and last month values (e.g., change 0-30 to 1-31)\n",
    "        first_day_month = month.index[0].astype('int') + 1 \n",
    "        last_day_month = month.index[-1].astype('int') + 1\n",
    "        # Subset our yearly data by each months values.\n",
    "        month_len = snow_data_transposed[:,:,first_day_month:last_day_month]\n",
    "        # Now we can take the mean of year month, since our 3rd dimension is the subset of days for that month.\n",
    "        # This will reduce our dimensions down to 2, since we're taking the average over a month. \n",
    "        mean = np.mean(month_len, axis = 2)\n",
    "        # Append monthly mean values to list for a single year. \n",
    "        new_list.append(mean)\n",
    "    # Append single year lists to yearly list, which will contain all the monthly means per year. \n",
    "    snow_monthly_means_list.append(new_list)\n",
    "# Converts list to array. \n",
    "snow_monthly_means_per_year_array = np.array(snow_monthly_means_list)\n",
    "np.shape(snow_monthly_means_per_year_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Annual Mean Snow Cover for Each Year<a class=\"anchor\" id=\"bullet4\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmunn\\AppData\\Local\\Temp/ipykernel_25648/2507094329.py:23: RuntimeWarning: Mean of empty slice\n",
      "  annual_snow = np.nanmean(snow_data_transposed, axis = 2)\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to append our yearly means to\n",
    "snow_year_list = []\n",
    "for i in range(len(snow_ds)):\n",
    "    # Get subdatasets of first snow fraction dataset ('Sierra2001.h5').\n",
    "    datasets = gdal.Open(snow_ds[i], gdal.GA_ReadOnly).GetSubDatasets()\n",
    "\n",
    "    #(sds[3] is to choose the 4th dataset in the subdirectory (i.e., snow fraction). \n",
    "    #The second bracket [0] is needed to open the dataset.\n",
    "    snow_data = gdal.Open(datasets[3][0])\n",
    "\n",
    "    #Changes the selected dataset into an array.\n",
    "    snow_data_array = snow_data.ReadAsArray()\n",
    "\n",
    "    #Converts the variables to 'float' to allow us to convert NA values (255) to nans\n",
    "    #We also convert 0s to nans so that when plotted on base map, only areas where data is present are shown\n",
    "    snow_data_float=snow_data_array.astype('float')\n",
    "    snow_data_float[snow_data_float == 255] = np.nan\n",
    "    snow_data_float[snow_data_float == 0 ] = np.nan\n",
    "\n",
    "    snow_data_transposed = np.transpose(snow_data_float)\n",
    "    # The dimensions of our data is ydim, xdim, days. \n",
    "    # Therefore, we can take the mean by our 3rd dimension to find the annual values of snow.\n",
    "    annual_snow = np.nanmean(snow_data_transposed, axis = 2)\n",
    "    # Append yearly values to a list. \n",
    "    snow_year_list.append(annual_snow)\n",
    "# Convert list to an array. \n",
    "snow_year_array = np.array(snow_year_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Snow Cover Anomolies Per Month Per Year<a class=\"anchor\" id=\"bullet5\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the mean of each monthly mean\n",
    "# Note: to get true mean (weighted mean), we would need to take the mean of the cumulatice days of a single month, then divide by the number of days. \n",
    "# However, since the sample size only varies by one day every four years (leap years), this will give us near identical values. \n",
    "\n",
    "# Since we already have the mean of each month per year stored in a 4d array (year, month, ydim, xdim), we can take the mean the year column (axis 0), since each year columnm\n",
    "# stores a 3d array for each year. This function will effectively take the mean of each month, ydim, and xdim to end up with a single 3d array. \n",
    "mean_of_months = np.mean(snow_monthly_means_per_year_array, axis = 0)\n",
    "\n",
    "# Create empty list to put anomalies in.\n",
    "monthly_anomalies = []\n",
    "# For loop through each year in the dataset (19)\n",
    "for i in range(len(snow_monthly_means_per_year_array[:])):\n",
    "    # For loop through each year\n",
    "    selected_anomaly_year = snow_monthly_means_per_year_array[i]\n",
    "    # Create an empty list to append our monthly anomalies to\n",
    "    month_anomalies_list = []\n",
    "    # For loop through each month of each year\n",
    "    for j in range(len(selected_anomaly_year[:])):\n",
    "        # Subtract our monthly means from our annual means for each month\n",
    "        monthly_anom = selected_anomaly_year[j] - mean_of_months[j]\n",
    "        # Append list with the calculated monthly anomalies.\n",
    "        month_anomalies_list.append(monthly_anom)\n",
    "    # Append list with list comprised of monthly anomalies\n",
    "    # Final list values will be the same shape as the monthly_means_per_year dataset since we are calculting monthly anomalies for each year.\n",
    "    monthly_anomalies.append(month_anomalies_list)\n",
    "# Transform to list to arrays\n",
    "snow_anom_array = np.array(monthly_anomalies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Indivdual Snow Cover Years and Months<a class=\"anchor\" id=\"bullet6\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of list is year, month, ydim, xdim\n",
    "np.shape(snow_monthly_means_per_year_array)\n",
    "\n",
    "# Select the first year of our dataset.\n",
    "snow_year_one = snow_monthly_means_per_year_array[0,:,:,:]\n",
    "# Transpose data so that the dataset is ordered as: [xdim, ydim, month]\n",
    "snow_year_one_transposed = np.transpose(snow_year_one, (1,2,0))\n",
    "\n",
    "\n",
    "#Select the first year of the anomaly dataset. \n",
    "snow_year_one_anom = snow_anom_array[0,:,:,:]\n",
    "snow_year_one_anom_transposed = np.transpose(snow_year_one)\n",
    "\n",
    "# Select the first month of the first year\n",
    "snow_year_one_month_one_anom = snow_year_one_anom[0,:,:]\n",
    "# Transpose to make months the 3rd dimension\n",
    "snow_y_one_m_one_anom_t = snow_year_one_month_one_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Albedo Data<a class=\"anchor\" id=\"bullet7\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glob together all of the albedo datasets.\n",
    "albedo = glob.glob('SierraAlbedo*.h5')\n",
    "albedo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Monthly Albedo Averages<a class=\"anchor\" id=\"bullet8\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subdatasets of first snow fraction dataset ('SierraAlbedo2001.h5').\n",
    "albedo_monthly_mean_list = []\n",
    "for i in range(len(albedo)):\n",
    "    dataset = gdal.Open(albedo[i], gdal.GA_ReadOnly)\n",
    "\n",
    "\n",
    "    #Changes the selected dataset into an array.\n",
    "    albedo_array = dataset.ReadAsArray()\n",
    "\n",
    "    albedo_float = albedo_array.astype('float')\n",
    "    albedo_float[albedo_float == 65535] = np.nan\n",
    "    albedo_float[albedo_float == 0] = np.nan\n",
    "\n",
    "\n",
    "    albedo_test = np.transpose(albedo_float)\n",
    "    \n",
    "    # Make a variable for the starting year of each water year.\n",
    "    year =  i + 2000\n",
    "    # Creates a variable for the first date in the water year. \n",
    "    start_date = pd.to_datetime(str(year) + '-10-01')\n",
    "    end_date = pd.to_datetime(str(int(year) + 1) + '-09-30')\n",
    "    # Creates a list of datetimes based on each year in our dataset.\n",
    "    albedo_year_month_date = pd.Series(pd.date_range(start = start_date, end = end_date, freq=\"d\"))\n",
    "    #Need to create an empty list to append our mean values to. \n",
    "    new_list = []\n",
    "    # For loop to calculate the mean for each month per year. \n",
    "    for j in range (1, 13):\n",
    "        # Subset the date year based on month.\n",
    "        month = albedo_year_month_date[albedo_year_month_date.dt.month == j]\n",
    "        \n",
    "        first_day_month = month.index[0].astype('int') + 1 \n",
    "        last_day_month = month.index[-1].astype('int') + 1\n",
    "        \n",
    "        # Subset dataset by each month.\n",
    "        month_len = albedo_test[:,:,first_day_month:last_day_month]\n",
    "        # Take the mean of each month per year. \n",
    "        mean = np.mean(month_len, axis = 2)\n",
    "        # Append mean values to list per year. \n",
    "        new_list.append(mean)\n",
    "    # Append year lists to empty list. \n",
    "    albedo_monthly_mean_list.append(new_list)\n",
    "# Converts list to array. \n",
    "albedo_monthly_mean_array = np.array(albedo_monthly_mean_list)\n",
    "np.shape(albedo_monthly_mean_array)\n",
    "\n",
    "# Since we're interested in albedo rates, we need to divide our values by the divisor(10000) \n",
    "# Create empty list to put values in \n",
    "albedo_monthly_divisor = []\n",
    "# Select year\n",
    "for i in range(len(albedo_monthly_mean_array[:])):\n",
    "    # albedo_monthly_mean_array[i] chooses the first year in the dataset since the first dim is year\n",
    "    year_divisor = albedo_monthly_mean_array[i]\n",
    "    sub_list = []\n",
    "    for j in range(len(year_divisor[:])):\n",
    "        # year_divisor[j] chooses the first mean month of the selected year\n",
    "        # We divide each value in our array by 10000 to get the real value of each cell\n",
    "        albedo_monthly_anom = year_divisor[j]/10000\n",
    "        # Append each monthly value to a list\n",
    "        sub_list.append(albedo_monthly_anom)\n",
    "    # Append each year to list\n",
    "    albedo_monthly_divisor.append(sub_list)\n",
    "# Convert list to array\n",
    "albedo_divisor_array = np.array(albedo_monthly_divisor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Albedo Anomalies Per Month Per Year <a class=\"anchor\" id=\"bullet10\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the mean of each monthly mean\n",
    "# Note: to get true mean (weighted mean), we would need to take the mean of the cumulatice days of a single month, then divide by the number of days. \n",
    "# However, since the sample size only varies by one day every four years (leap years), this will give us near identical values. \n",
    "month_mean_albedo = np.mean(albedo_divisor_array, axis = 0)\n",
    "np.shape(month_mean_albedo)\n",
    "\n",
    "\n",
    "# Create empty list to put values in \n",
    "albedo_monthly_anom = []\n",
    "# Select range in years (1, 19)\n",
    "for i in range(len(albedo_divisor_array[:])):\n",
    "   # albedo_divisor_array[i] chooses the first year in the dataset since the first dim is year\n",
    "    albedo_year_anom = albedo_divisor_array[i]\n",
    "    # Create an empty list to append nest for loop values to.\n",
    "    sub_list = []\n",
    "    # select range in months per year(1, 12)\n",
    "    for j in range(len(albedo_year_anom[:])):\n",
    "        # albedo_year_anom[j] chooses the first mean month of the selected year\n",
    "        # Since we've already calculated the annual monthly mean over 19 years, we can subtract each \n",
    "        # monthly mean from the annual monthly mean to see how each years monthly means deviate from the annual monthly mean   \n",
    "        month_anom = albedo_year_anom[j] - month_mean_albedo[j]\n",
    "        # Append monthly anomolies to a list \n",
    "        sub_list.append(month_anom)\n",
    "    # Append monthly anomolies per year to a list\n",
    "    albedo_monthly_anom.append(sub_list)\n",
    "# Convert anomaly list to an array\n",
    "anom_array = np.array(albedo_monthly_anom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Indivdual Albedo Years and Months <a class=\"anchor\" id=\"bullet11\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1841, 1334)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the first year of the \n",
    "albedo_year_one_mean = albedo_divisor_array[0,:,:,]\n",
    "albedo_year_three_mean = albedo_divisor_array[2,:,:,]\n",
    "np.shape(albedo_year_one_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Datasets to GeoTIFFs <a class=\"anchor\" id=\"bullet12\"></a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Geospatial Inputs <a class=\"anchor\" id=\"bullet3\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Since relevant Geospatial Metadata is the same for snow cover and albedo, we can use the same inputs for functions below. \n",
    "\n",
    "# x dimension of array\n",
    "xdim = snow_data_array.shape[1]\n",
    "# y dimension of array\n",
    "ydim = snow_data_array.shape[2]\n",
    "# Projection data of sample GeoTiff\n",
    "projection = 'PROJCS[\"Albers Conical Equal Area\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"latitude_of_center\",0],PARAMETER[\"longitude_of_center\",-120],PARAMETER[\"standard_parallel_1\",34],PARAMETER[\"standard_parallel_2\",40.5],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",-4000000],UNIT[\"meters\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]'\n",
    "# transformation data of array\n",
    "# Pull refrencing matrix from h5 file.\n",
    "ref_matrix_meta = snow_data.GetMetadata()['Grid_MODIS_GRID_500m_ReferencingMatrix'].split()\n",
    "referencing_matrix = [int(ref_matrix_meta[2]), int(ref_matrix_meta[1]), int(ref_matrix_meta[0]), int(ref_matrix_meta[5]), int(ref_matrix_meta[4]), int(ref_matrix_meta[3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Array to Geotiff <a class=\"anchor\" id=\"bullet13\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables needed to get the function to run. \n",
    "def SingleGeotiff(raster_name, data, height, width, geotransform, wkt):\n",
    "    # Set driver to 'GTiff' for Geotiffs\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    # Create a GeoTIFF, where:\n",
    "    # name = raster name,\n",
    "    # width = 1st dim,\n",
    "    # height = 2nd dim,\n",
    "    # 1 = 3rd dim (effectively making it a two-dimensional object),\n",
    "    # GDT_Float32 = number format \n",
    "    dataset = driver.Create(\n",
    "        raster_name,\n",
    "        width,\n",
    "        height,\n",
    "        1,\n",
    "        gdal.GDT_Float32)\n",
    "\n",
    "    dataset.SetGeoTransform((\n",
    "     geotransform))\n",
    "\n",
    "    dataset.SetProjection(wkt)\n",
    "    dataset.GetRasterBand(1).WriteArray(data)\n",
    "    dataset.FlushCache()  # Write to disk.\n",
    "    return dataset, dataset.GetRasterBand(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x0000021E16ECC1E0> >,\n",
       " <osgeo.gdal.Band; proxy of <Swig Object of type 'GDALRasterBandShadow *' at 0x0000021E0BBD2450> >)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SingleGeotiff('year_one_month_one_anom.tif', snow_y_one_m_one_anom_t, ydim, xdim, referencing_matrix, projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Stacked Array into Multiple Geotiffs <a class=\"anchor\" id=\"bullet14\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_one_t = np.transpose(snow_year_one)\n",
    "path = 'tif/2001'\n",
    "for i in range(len(snow_year_one) -1):\n",
    "    dest = ('month' + str(i + 1) + 'year_2001.tif') \n",
    "    name = os.path.join(path, dest)\n",
    "    data = snow_year_one_transposed[:,:,i]\n",
    "    SingleGeotiff(name, data, ydim, xdim, referencing_matrix, projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tif/2001\\\\month10year_2001.tif',\n",
       " 'tif/2001\\\\month11year_2001.tif',\n",
       " 'tif/2001\\\\month1year_2001.tif',\n",
       " 'tif/2001\\\\month2year_2001.tif',\n",
       " 'tif/2001\\\\month3year_2001.tif',\n",
       " 'tif/2001\\\\month4year_2001.tif',\n",
       " 'tif/2001\\\\month5year_2001.tif',\n",
       " 'tif/2001\\\\month6year_2001.tif',\n",
       " 'tif/2001\\\\month7year_2001.tif',\n",
       " 'tif/2001\\\\month8year_2001.tif',\n",
       " 'tif/2001\\\\month9year_2001.tif']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgs = glob.glob('tif/2001/month*year*.tif')\n",
    "wgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the following variables to the file you want to convert (inputfile)\n",
    "# and what you want to name your output file (outputfile)\n",
    "for i in range(len(wgs)):\n",
    "    inputfile = wgs[i]\n",
    "    outputfile = \"wgs_test\" + str(i) + \".tif\"\n",
    "    #Do not change the following line, it will reproject the geotiff file\n",
    "    ds = gdal.Warp(outputfile, inputfile, dstSRS=\"+proj=longlat +datum=WGS84 +no_defs\", dstNodata = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Stacked Array to Geotiff <a class=\"anchor\" id=\"bullet15\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StackedGeotiff(name, array, geo_transform, projection):\n",
    "    \n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "\n",
    "    DataSet = driver.Create(name, array.shape[2], array.shape[1], array.shape[0], gdal.GDT_Float32)\n",
    "    DataSet.SetGeoTransform(geo_transform)\n",
    "    DataSet.SetProjection(projection)\n",
    "    for i, image in enumerate(array, 1):\n",
    "        DataSet.GetRasterBand(i).WriteArray( image )\n",
    "    DataSet.FlushCache()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'year_one_stack.tif'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StackedGeotiff('year_one_stack.tif', snow_year_one, referencing_matrix, projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Geotiff to WGS84 Coordinate System <a class=\"anchor\" id=\"bullet15\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the following variables to the file you want to convert (inputfile)\n",
    "# and what you want to name your output file (outputfile)\n",
    "inputfile = \"sample_stack.tif\"\n",
    "outputfile = \"wgs_sample_stack.tif\"\n",
    "\n",
    "ds = gdal.Warp(outputfile, inputfile, dstSRS=\"+proj=longlat +datum=WGS84 +no_defs\", dstNodata = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Geotiff to NetCDF File <a class=\"anchor\" id=\"bullet16\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff = rio.open_rasterio('sample_stack.tif')\n",
    "tiff.to_netcdf('sample_stack.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Rasters Using Leafmap <a class=\"anchor\" id=\"bullet17\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_one = (\"wgs_test4.tif\")\n",
    "# m = leafmap.Map(draw_control=False, layers_control=True)\n",
    "# m.add_raster(input_one, colormap='terrain', layer_name='layer_one')\n",
    "# m"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5f12541159748febc435e9ce37f11542d537a74020e77854a807a32ae0dfc0f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('eds223')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
