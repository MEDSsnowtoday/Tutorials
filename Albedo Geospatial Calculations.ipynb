{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import plotly.graph_objects as go\n",
    "import h5py\n",
    "from matplotlib.pyplot import *\n",
    "import imageio\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SierraAlbedo2001.h5',\n",
       " 'SierraAlbedo2002.h5',\n",
       " 'SierraAlbedo2003.h5',\n",
       " 'SierraAlbedo2004.h5',\n",
       " 'SierraAlbedo2005.h5',\n",
       " 'SierraAlbedo2006.h5',\n",
       " 'SierraAlbedo2007.h5',\n",
       " 'SierraAlbedo2008.h5',\n",
       " 'SierraAlbedo2009.h5',\n",
       " 'SierraAlbedo2010.h5',\n",
       " 'SierraAlbedo2011.h5',\n",
       " 'SierraAlbedo2012.h5',\n",
       " 'SierraAlbedo2013.h5',\n",
       " 'SierraAlbedo2014.h5',\n",
       " 'SierraAlbedo2015.h5',\n",
       " 'SierraAlbedo2016.h5',\n",
       " 'SierraAlbedo2017.h5',\n",
       " 'SierraAlbedo2018.h5',\n",
       " 'SierraAlbedo2019.h5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Glob together all of the albedo datasets.\n",
    "albedo = glob.glob('*.h5')\n",
    "albedo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Monthly Albedo Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subdatasets of first snow fraction dataset ('SierraAlbedo2001.h5').\n",
    "time_list = []\n",
    "for i in range(len(albedo)):\n",
    "    dataset = gdal.Open(albedo[i], gdal.GA_ReadOnly)\n",
    "\n",
    "\n",
    "    #Changes the selected dataset into an array.\n",
    "    albedo_array = dataset.ReadAsArray()\n",
    "\n",
    "    albedo_float = albedo_array.astype('float')\n",
    "    albedo_float[albedo_float == 65535] = np.nan\n",
    "    albedo_float[albedo_float == 0] = np.nan\n",
    "\n",
    "\n",
    "    albedo_test = np.transpose(albedo_float)\n",
    "    \n",
    "    # Make a variable for the starting year of each water year.\n",
    "    year =  i + 2000\n",
    "    # Creates a variable for the first date in the water year. \n",
    "    year_month = (str(year) + \"-10-01\")\n",
    "    # Creates a list of datetimes based on each year in our dataset.\n",
    "    year_month_date = pd.Series(pd.date_range((year_month), periods =(len(albedo_array)), freq=\"d\"))\n",
    "    #Need to create an empty list to append our mean values to. \n",
    "    new_list = []\n",
    "    # For loop to calculate the mean for each month per year. \n",
    "    for j in range (1, 13):\n",
    "        # Subset the date year based on month.\n",
    "        month = year_month_date[year_month_date.dt.month == j]\n",
    "        # Subset dataset by each month.\n",
    "        month_len = albedo_test[:,:,(list(month.index))]\n",
    "        # Take the mean of each month per year. \n",
    "        mean = np.mean(month_len, axis = 2)\n",
    "        # Append mean values to list per year. \n",
    "        new_list.append(mean)\n",
    "    # Append year lists to empty list. \n",
    "    time_list.append(new_list)\n",
    "# Converts list to array. \n",
    "date_array = np.array(time_list)\n",
    "np.shape(date_array)\n",
    "\n",
    "# Since we're interested in albedo rates, we need to divide our values by the divisor(10000) \n",
    "\n",
    "# Create empty list to put values in \n",
    "month_divisor = []\n",
    "# Select year\n",
    "for i in range(len(date_array[:])):\n",
    "    year_divisor = date_array[i]\n",
    "    sub_list = []\n",
    "    for j in range(len(year_divisor[:])):\n",
    "        month_anom = year_divisor[j]/10000\n",
    "        sub_list.append(month_anom)\n",
    "    month_divisor.append(sub_list)\n",
    "divisor_array = np.array(month_divisor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Annual Mean Albedo Percentage for Each Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1841, 1334)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes the mean of each monthly mean\n",
    "# Note: to get true mean (weighted mean), we would need to take the mean of the cumulatice days of a single month, then divide by the number of days. \n",
    "# However, since the sample size only varies by one day every four years (leap years), this will give us near identical values. \n",
    "month_mean_albedo = np.mean(divisor_array, axis = 0)\n",
    "np.shape(month_mean_albedo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.567209  , 0.57156503, 0.57293718, ..., 0.81132615, 0.81249525,\n",
       "              nan])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(month_mean_albedo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Monthly Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list to put values in \n",
    "monthly_anom = []\n",
    "# Select year\n",
    "for i in range(len(divisor_array[:])):\n",
    "    year_anom = divisor_array[i]\n",
    "    sub_list = []\n",
    "    for j in range(len(year_anom[:])):\n",
    "        month_anom = year_anom[j] - month_mean_albedo[j]\n",
    "        sub_list.append(month_anom)\n",
    "    monthly_anom.append(sub_list)\n",
    "anom_array = np.array(monthly_anom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Indivdual Years and Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1841, 1334)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert our 3d mean annual list to array then select a single year.\n",
    "year_array = np.array(month_divisor)\n",
    "year_one_mean = year_array[0,:,:,]\n",
    "year_three_mean = year_array[2,:,:,]\n",
    "np.shape(year_one_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_one_anom = anom_array[0]\n",
    "year_one_anom = np.transpose(year_one_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_one_month_one_anom = anom_array[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts list to array. \n",
    "date_array = np.array(time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset our data to select year one (0 in this case)\n",
    "year_one = date_array[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1841, 1334, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose data so that the dataset is ordered as: [xdim, ydim, month]\n",
    "year_one_transposed = np.transpose(year_one, (1,2,0))\n",
    "np.shape(year_one_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1841, 1334)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_one_month_one = year_one_transposed[:,:,0]\n",
    "np.shape(year_one_month_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Gif of a Single Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create an empty list.\n",
    "    filenames = []\n",
    "    \n",
    "    for i in range (12):\n",
    "        # 3rd dimension is day. \n",
    "        total_d = year_one_anom[:,:,i] \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(total_d, interpolation = 'nearest')\n",
    "        plt.title('MODIS_GRID_500m 2001 Snow Cover Day: ' + str(i), fontsize = 20, fontweight='bold')\n",
    "        \n",
    "        filename = f'{i}.png'\n",
    "        filenames.append(filename)\n",
    "        \n",
    "        # save frame\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "        \n",
    "            \n",
    "    with imageio.get_writer('year_2.gif', mode='I') as writer:\n",
    "        for filename in filenames:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "    for filename in set(filenames):\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Monthly Averages to Geotiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x dimension of array\n",
    "xdim = albedo_array.shape[1]\n",
    "# y dimension of array\n",
    "ydim = albedo_array.shape[2]\n",
    "# Projection data of sample GeoTiff\n",
    "projection = 'PROJCS[\"Albers Conical Equal Area\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"latitude_of_center\",0],PARAMETER[\"longitude_of_center\",-120],PARAMETER[\"standard_parallel_1\",34],PARAMETER[\"standard_parallel_2\",40.5],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",-4000000],UNIT[\"meters\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]'\n",
    "# transformation data of array\n",
    "# Pull refrencing matrix from h5 file.\n",
    "ref_matrix_meta = dataset.GetMetadata()['Grid_MODIS_GRID_500m_ReferencingMatrix'].split()\n",
    "referencing_matrix = [int(ref_matrix_meta[2]), int(ref_matrix_meta[1]), int(ref_matrix_meta[0]), int(ref_matrix_meta[5]), int(ref_matrix_meta[4]), int(ref_matrix_meta[3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Single Layer to Geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SingleGeotiff(raster_name, data, height, width, geotransform, wkt):\n",
    "    \n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "\n",
    "    dataset = driver.Create(\n",
    "        raster_name,\n",
    "        width,\n",
    "        height,\n",
    "        1,\n",
    "        gdal.GDT_Float32)\n",
    "\n",
    "    dataset.SetGeoTransform((\n",
    "     geotransform))\n",
    "\n",
    "    dataset.SetProjection(wkt)\n",
    "    dataset.GetRasterBand(1).WriteArray(data)\n",
    "    dataset.FlushCache()  # Write to disk.\n",
    "    return dataset, dataset.GetRasterBand(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x0000015FBA4F2E70> >,\n",
       " <osgeo.gdal.Band; proxy of <Swig Object of type 'GDALRasterBandShadow *' at 0x0000015FBA499450> >)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SingleGeotiff('Annual_Janurary.tif', month_mean_albedo[0], ydim, xdim, referencing_matrix, projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Stacked Array to Stacked Geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StackedGeotiff(name, array, geo_transform, projection):\n",
    "    \n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "\n",
    "    DataSet = driver.Create(name, array.shape[2], array.shape[1], array.shape[0], gdal.GDT_Float32)\n",
    "    DataSet.SetGeoTransform(geo_transform)\n",
    "    DataSet.SetProjection(projection)\n",
    "    for i, image in enumerate(array, 1):\n",
    "        DataSet.GetRasterBand(i).WriteArray( image )\n",
    "    DataSet.FlushCache()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StackedGeotiff('year_one_stack.tif', year_one, referencing_matrix, projection)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5f12541159748febc435e9ce37f11542d537a74020e77854a807a32ae0dfc0f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('eds223')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
